{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Human Detection Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import random\n",
    "from skimage.feature import hog\n",
    "from skimage import exposure\n",
    "from sklearn import svm\n",
    "from sklearn.decomposition import PCA\n",
    "from skimage.transform import pyramid_gaussian\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showImg(im,text = 'xd'):\n",
    "    cv2.imshow(text,im)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lectura de imágenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def leerFotos(path):\n",
    "    os.chdir(path)\n",
    "    listaPos = os.listdir()\n",
    "    fotosDic = {}\n",
    "    for i in range(len(listaPos)):\n",
    "        fotosDic[i] = cv2.imread(listaPos[i],0)\n",
    "    return fotosDic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fotos Tain "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def duplicaTrani(fotos):\n",
    "    indx = len(fotos)\n",
    "    for i in range(len(fotos)):\n",
    "        fotos[indx+i] = cv2.flip(fotos[i], 1)\n",
    "        \n",
    "    return fotos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'C:\\\\Users\\\\Jhonny Chicaiza\\\\Desktop\\\\Human_Detection_Project-master\\\\train_pos'\n",
    "fotosPosTrain0 = leerFotos(path)\n",
    "fotosPosTrain0 = duplicaTrani(fotosPosTrain0)\n",
    "\n",
    "path = 'C:\\\\Users\\\\Jhonny Chicaiza\\\\Desktop\\\\Human_Detection_Project-master\\\\train_neg'\n",
    "fotosNegTrainSinTratar = leerFotos(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fotos Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'C:\\\\Users\\Jhonny Chicaiza\\\\Desktop\\\\Human_Detection_Project-master\\\\Test\\\\pos'\n",
    "fotosTest0 = leerFotos(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recorte Train Neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generaImagenesRecortadas(winSize,dataNeg,numeroCortesxPh = 20):\n",
    "    rowsFotoPersona = winSize[0]\n",
    "    colsFotoPersona = winSize[1]\n",
    "    \n",
    "    fotosNegTrain = {}\n",
    "    for i in range(len(dataNeg)):      \n",
    "        rowsFotoEntorno = dataNeg[i].shape[0]\n",
    "        colsFotoEntorno = dataNeg[i].shape[1]\n",
    "        dimCol = colsFotoEntorno - colsFotoPersona\n",
    "        dimRow = rowsFotoEntorno - rowsFotoPersona\n",
    "        \n",
    "        for j in range(numeroCortesxPh):    \n",
    "            randRow = random.randint(0,dimRow-1)\n",
    "            randCol = random.randint(0,dimCol-1)\n",
    "            randomImage = dataNeg[i][randRow:randRow + rowsFotoPersona ,randCol: randCol + colsFotoPersona]\n",
    "            fotosNegTrain[j+numeroCortesxPh*i] = randomImage\n",
    "            \n",
    "    return fotosNegTrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "winSize = fotosPosTrain0[0].shape\n",
    "fotosNegTrain0 = generaImagenesRecortadas(winSize,fotosNegTrainSinTratar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tratamiento de la imagenes Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ampliazcion Rango Dinámico && Suavizado && Normlizacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ampRangoSet(fotos):\n",
    "    fotSal = {}\n",
    "    for i in range(len(fotos)):\n",
    "        r1 = np.min(fotos[i])\n",
    "        r2 = np.max(fotos[i])\n",
    "        fotSal[i] = np.float32(fotos[i])\n",
    "        fotSal[i] = 255*(fotSal[i]-r1)/(r2-r1)\n",
    "        fotSal[i] = np.uint8(fotSal[i])\n",
    "        \n",
    "    return fotSal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trataFotos(fotos,kernelSize = 3):\n",
    "    fotSal = {}\n",
    "    ## Ampliación del rango\n",
    "    fotSal = ampRangoSet(fotos)\n",
    "\n",
    "    ## Suavizado\n",
    "    #kernel = np.ones((kernelSize,kernelSize))/(kernelSize**2)\n",
    "    n = kernelSize #tamaño del filtro\n",
    "    sigma = 3 #desviación de la gaussiana\n",
    "    mask = cv2.getGaussianKernel(n, sigma)*cv2.getGaussianKernel(n, sigma).T\n",
    "    \n",
    "    for i in range(len(fotSal)):\n",
    "        fotSal[i] = cv2.filter2D(fotSal[i],-1,mask)\n",
    "        \n",
    "    return fotSal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dimFiltro = 7\n",
    "fotosNegTrain = trataFotos(fotosNegTrain0,dimFiltro)\n",
    "fotosPosTrain = trataFotos(fotosPosTrain0,dimFiltro)\n",
    "fotosTest = trataFotos(fotosTest0,dimFiltro)\n",
    "\n",
    "fotosNegTrain[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracción de Caracterísitcas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hog\n",
    "    L1\n",
    "       Normalization using L1-norm.\n",
    "    L1-sqrt\n",
    "       Normalization using L1-norm, followed by square root.\n",
    "    L2\n",
    "       Normalization using L2-norm.\n",
    "    L2-Hys\n",
    "       Normalization using L2-norm, followed by limiting the\n",
    "       maximum values to 0.2 (`Hys` stands for `hysteresis`) and\n",
    "       renormalization using L2-norm. (default)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orientations    = 9\n",
    "pixels_per_cell = (8, 8)\n",
    "cells_per_block = (2, 2)\n",
    "block_norm      = 'L2' \n",
    "visualize       = False\n",
    "visualise       = None\n",
    "transform_sqrt  = True\n",
    "feature_vector  = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def featuresExtrac(imagenes,esPositivo):    \n",
    "    ## Tamaño del vector\n",
    "    auxDim = hog(imagenes[0],orientations,pixels_per_cell,cells_per_block,block_norm,visualize,visualise,transform_sqrt,feature_vector)\n",
    "    tamHog = len(auxDim)\n",
    "    \n",
    "    #inicializamos la matriz que guarda los imagenes vectolizados\n",
    "    fdImagenesHog = np.zeros((len(imagenes),tamHog))\n",
    "    \n",
    "    for i in range(len(imagenes)):\n",
    "        fdImagenesHog[i,:] = hog(imagenes[i],orientations,pixels_per_cell,cells_per_block,block_norm,visualize,visualise,transform_sqrt,feature_vector)\n",
    "        \n",
    "    #asignamos el vector de clases(y) \n",
    "    if esPositivo:\n",
    "        y = np.ones((len(imagenes),1))\n",
    "    else:\n",
    "        y = np.zeros((len(imagenes),1))\n",
    "\n",
    "    return fdImagenesHog,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdPosTrainHog,yPos = featuresExtrac(fotosPosTrain,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdNegTrainHog,yNeg = featuresExtrac(fotosNegTrain,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdTrainHog = np.vstack((fdPosTrainHog,fdNegTrainHog))\n",
    "y = np.vstack((yPos,yNeg))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrenamiento del modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HOG Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clfHog = svm.LinearSVC(C=0.01)\n",
    "clfHog.fit(fdTrainHog[:,:],y[:,:].ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clfHog.score(fdPosTrainHog,yPos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clfHog.score(fdNegTrainHog,yNeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Slide Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def slidWindow(imagen,maskHeight = 134,maskWidth = 70,step = 10):\n",
    "    arrayImagen = []\n",
    "    \n",
    "    for i in range(0,imagen.shape[0]-maskHeight,step):        \n",
    "        for j in range(0,imagen.shape[1]-maskWidth,step):\n",
    "            arrayImagen.append((i,j,imagen[i:i+maskHeight, j:j+maskWidth]))\n",
    "    \n",
    "    return arrayImagen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pyramid Gaussian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estudiaFoto(im,winSize,clfHog,ratio = 2,margen = 0):#Ratio de reducción\n",
    "    # List to store the detections\n",
    "    hdetections = []\n",
    "    detectJump = 0;\n",
    "    \n",
    "    for scaLev,imScaled in enumerate(pyramid_gaussian(im,downscale=ratio,multichannel=False)):\n",
    "        if (imScaled.shape[0] >= winSize[0] and imScaled.shape[1] >= winSize[1]):\n",
    "            for (x,y,imVentana) in slidWindow(imScaled):\n",
    "                if (detectJump <= 0):\n",
    "                    fdHog = hog(imVentana,orientations,pixels_per_cell,cells_per_block,block_norm,visualize,visualise,transform_sqrt,feature_vector);\n",
    "                    predHog = clfHog.predict(fdHog.reshape(1,-1))\n",
    "                    acc = clfHog.decision_function(fdHog.reshape(1,-1))[0]\n",
    "                    \n",
    "                    if (predHog == 1 and acc > margen):\n",
    "                        detectJump = 10\n",
    "                        hdetections.append((x*(ratio**scaLev),y*(ratio**scaLev),int(winSize[1]*(ratio**scaLev)),int(winSize[0]*(ratio**scaLev))))\n",
    "                detectJump -= 1;\n",
    "    return hdetections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prueba del Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def muestraResultado(detections,im):\n",
    "    color = (255)\n",
    "    for (x, y,w, h) in detections:\n",
    "            # Draw the detections\n",
    "            cv2.rectangle(im, (y, x), (y+w, x+h), color, thickness=1)\n",
    "    cv2.imshow(\"Deteciones\", im)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "humanDetec = estudiaFoto(fotosTest[0],winSize,clfHog,ratio=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(humanDetec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "muestraResultado(humanDetec,fotosTest[0].copy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prueba solo Una imagen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "listOk = []\n",
    "partImagen = slidWindow(fotosTest[7])\n",
    "lim = 0.5\n",
    "for i in range(len(partImagen)):\n",
    "    pruebaHog = hog(partImagen[i][2],orientations,pixels_per_cell,cells_per_block,block_norm,visualize,visualise,transform_sqrt,feature_vector);\n",
    "    precis = clfHog.decision_function(pruebaHog.reshape(1,-1))[0]\n",
    "    if (1 == clfHog.predict(pruebaHog.reshape(1,-1)) and precis > lim):\n",
    "        listOk.append(i);\n",
    "        showImg(partImagen[i][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(partImagen))\n",
    "print(len(listOk))\n",
    "print(listOk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('img ', fotosTest[0])\n",
    "cv2.imshow('trozo test ', partImagen[3520][2])\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pruebaHog = hog(partImagen[3520][2],orientations,pixels_per_cell,cells_per_block,block_norm,visualize,visualise,transform_sqrt,feature_vector);\n",
    "porce = clfHog.decision_function(pruebaHog.reshape(1,-1))[0]\n",
    "print(porce)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py37vision] *",
   "language": "python",
   "name": "conda-env-py37vision-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
