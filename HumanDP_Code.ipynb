{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Human Detection Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import random\n",
    "from skimage.feature import hog\n",
    "from skimage import exposure\n",
    "from sklearn import svm\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lectura de imagenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def leerFotos(path):\n",
    "    os.chdir(path)\n",
    "    listaPos = os.listdir()\n",
    "    fotosDic = {}\n",
    "    for i in range(len(listaPos)):\n",
    "        fotosDic[i] = cv2.imread(listaPos[i],0)\n",
    "    return fotosDic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'C:\\\\Users\\\\Jhonny Chicaiza\\\\Desktop\\\\Human_Detection_Project-master\\\\train_pos'\n",
    "fotosPosTrain = leerFotos(path)\n",
    "\n",
    "path = 'C:\\\\Users\\\\Jhonny Chicaiza\\\\Desktop\\\\Human_Detection_Project-master\\\\train_neg'\n",
    "fotosNegTrainSinTratar = leerFotos(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generaImagenesRecortadas(dataPos,dataNeg):    \n",
    "    numeroCortesxPh = 20      # Numero de recortadas aleatorias por foto\n",
    "    rowsFotoPersona = dataPos[0].shape[0]\n",
    "    colsFotoPersona = dataPos[0].shape[1]\n",
    "    \n",
    "    fotosNegTrain = {}\n",
    "    for i in range(len(dataNeg)):      \n",
    "        rowsFotoEntorno = dataNeg[i].shape[0]\n",
    "        colsFotoEntorno = dataNeg[i].shape[1]\n",
    "        dimCol = colsFotoEntorno - colsFotoPersona\n",
    "        dimRow = rowsFotoEntorno - rowsFotoPersona\n",
    "        \n",
    "        for j in range(numeroCortesxPh):    \n",
    "            randRow = random.randint(0,dimRow-1)\n",
    "            randCol = random.randint(0,dimCol-1)\n",
    "            randomImage = dataNeg[i][randRow:randRow + rowsFotoPersona ,randCol: randCol + colsFotoPersona]\n",
    "            fotosNegTrain[j+numeroCortesxPh*i] = randomImage\n",
    "            \n",
    "    return fotosNegTrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "fotosNegTrain = generaImagenesRecortadas(fotosPosTrain,fotosNegTrainSinTratar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracción de Caracterísitcas\n",
    "    L1\n",
    "       Normalization using L1-norm.\n",
    "    L1-sqrt\n",
    "       Normalization using L1-norm, followed by square root.\n",
    "    L2\n",
    "       Normalization using L2-norm.\n",
    "    L2-Hys\n",
    "       Normalization using L2-norm, followed by limiting the\n",
    "       maximum values to 0.2 (`Hys` stands for `hysteresis`) and\n",
    "       renormalization using L2-norm. (default)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "orientations    = 9\n",
    "pixels_per_cell = (8, 8)\n",
    "cells_per_block = (3, 3)\n",
    "block_norm      = 'L2'   \n",
    "visualize       = False\n",
    "visualise       = None\n",
    "transform_sqrt  = True\n",
    "feature_vector  = True\n",
    "multichannel    = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectolizarHOG(imagenes,esPositivo):\n",
    "    ### Esata funcion aplica HOG a todas las imagenes del diccionario\n",
    "    \n",
    "    #tamaño del vector\n",
    "    tamVector = len(hog(imagenes[0],orientations,pixels_per_cell,cells_per_block,block_norm,visualize,visualise,transform_sqrt,feature_vector,multichannel))\n",
    "\n",
    "    #inicializamos la matriz que guarda los imagenes vectolizados\n",
    "    fdImagenes = np.zeros((len(imagenes),tamVector))\n",
    "    \n",
    "    for i in range(len(imagenes)):\n",
    "        fdImagenes[i,:] = hog(imagenes[i],orientations,pixels_per_cell,cells_per_block,block_norm,visualize,visualise,transform_sqrt,feature_vector,multichannel)\n",
    "    \n",
    "    #asignamos el vector de clases(y) \n",
    "    if esPositivo:\n",
    "        y = np.ones((len(imagenes),1))\n",
    "    else:\n",
    "        y = np.zeros((len(imagenes),1))\n",
    "\n",
    "    return fdImagenes,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdPosTrain,yPos = vectolizarHOG(fotosPosTrain,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdNegTrain,yNeg = vectolizarHOG(fotosNegTrain,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4563, 6804)\n"
     ]
    }
   ],
   "source": [
    "fotosTrain = np.vstack((fdPosTrain,fdNegTrain))\n",
    "y = np.vstack((yPos,yNeg))\n",
    "\n",
    "print(fotosTrain.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_components= fotosTrain.shape[1]//2\n",
    "pca = PCA(n_components)\n",
    "dataPca = pca.fit_transform(fotosTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4563, 3402)"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataPca.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrenamiento del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=0.007, class_weight=None, dual=True, fit_intercept=True,\n",
       "          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "          verbose=0)"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = svm.LinearSVC(C = 0.007)\n",
    "clf.fit(dataPca,y.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9715808170515098"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#clf.score(fdPosTrain,yPos)\n",
    "datPosTrain = pca.transform(fdPosTrain)\n",
    "clf.score(datPosTrain,yPos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Slide Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "def secImagen(imagen,maskHeight = 134,maskWidth = 70,step = 10):\n",
    "    arrayImagen = {}\n",
    "    aux = 0\n",
    "    for i in range(0,imagen.shape[0]-maskHeight,step):        \n",
    "        for j in range(0,imagen.shape[1]-maskWidth,step):\n",
    "            arrayImagen[aux] = imagen[i:i+maskHeight, j:j+maskWidth]\n",
    "            aux = aux + 1\n",
    "    return arrayImagen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'C:\\\\Users\\Jhonny Chicaiza\\\\Desktop\\\\Human_Detection_Project-master\\\\Test\\\\pos'\n",
    "fotostest = leerFotos(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "partImagen = secImagen(fotostest[6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prueba del Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "listOk = []\n",
    "for i in range(len(partImagen)):\n",
    "    pruebaHog = hog(partImagen[i],orientations,pixels_per_cell,cells_per_block,block_norm,visualize,visualise,transform_sqrt,feature_vector,multichannel);\n",
    "    prueba = pca.transform(pruebaHog.reshape(1,-1))\n",
    "    if (1 == clf.predict(prueba.reshape(1,-1))):\n",
    "        listOk.append(i);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('img ', fotostest[6])\n",
    "cv2.imshow('xd ', partImagen[113])\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55\n",
      "[113, 291, 503, 836, 926, 1104, 1139, 1160, 1187, 1220, 1252, 1281, 1557, 1571, 1581, 1585, 1597, 1620, 1627, 1629, 1631, 1632, 1651, 1667, 1670, 1690, 1701, 1721, 1726, 1769, 1771, 1808, 1841, 1856, 1857, 1908, 1938, 1939, 1944, 1978, 2014, 2081, 2120, 2127, 2151, 2190, 2197, 2221, 2267, 2285, 2291, 2407, 2557, 2617, 2697]\n"
     ]
    }
   ],
   "source": [
    "print(len(listOk))\n",
    "print(listOk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py37vision] *",
   "language": "python",
   "name": "conda-env-py37vision-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
