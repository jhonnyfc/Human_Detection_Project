{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Human Detection Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import random\n",
    "from skimage.feature import hog\n",
    "from skimage import exposure\n",
    "from sklearn import svm\n",
    "from sklearn.decomposition import PCA\n",
    "from skimage.transform import pyramid_gaussian"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lectura de imágenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def leerFotos(path):\n",
    "    os.chdir(path)\n",
    "    listaPos = os.listdir()\n",
    "    fotosDic = {}\n",
    "    for i in range(len(listaPos)):\n",
    "        fotosDic[i] = cv2.imread(listaPos[i],0)\n",
    "    return fotosDic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fotos Tain "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'C:\\\\Users\\\\Jhonny Chicaiza\\\\Desktop\\\\Human_Detection_Project-master\\\\train_pos'\n",
    "fotosPosTrain = leerFotos(path)\n",
    "\n",
    "path = 'C:\\\\Users\\\\Jhonny Chicaiza\\\\Desktop\\\\Human_Detection_Project-master\\\\train_neg'\n",
    "fotosNegTrainSinTratar = leerFotos(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fotos Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'C:\\\\Users\\Jhonny Chicaiza\\\\Desktop\\\\Human_Detection_Project-master\\\\Test\\\\pos'\n",
    "fotosTest = leerFotos(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recorte Train Neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generaImagenesRecortadas(dataPos,dataNeg):    \n",
    "    numeroCortesxPh = 20      # Numero de recortadas aleatorias por foto\n",
    "    rowsFotoPersona = dataPos[0].shape[0]\n",
    "    colsFotoPersona = dataPos[0].shape[1]\n",
    "    \n",
    "    fotosNegTrain = {}\n",
    "    for i in range(len(dataNeg)):      \n",
    "        rowsFotoEntorno = dataNeg[i].shape[0]\n",
    "        colsFotoEntorno = dataNeg[i].shape[1]\n",
    "        dimCol = colsFotoEntorno - colsFotoPersona\n",
    "        dimRow = rowsFotoEntorno - rowsFotoPersona\n",
    "        \n",
    "        for j in range(numeroCortesxPh):    \n",
    "            randRow = random.randint(0,dimRow-1)\n",
    "            randCol = random.randint(0,dimCol-1)\n",
    "            randomImage = dataNeg[i][randRow:randRow + rowsFotoPersona ,randCol: randCol + colsFotoPersona]\n",
    "            fotosNegTrain[j+numeroCortesxPh*i] = randomImage\n",
    "            \n",
    "    return fotosNegTrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "fotosNegTrain = generaImagenesRecortadas(fotosPosTrain,fotosNegTrainSinTratar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracción de Caracterísitcas\n",
    "    L1\n",
    "       Normalization using L1-norm.\n",
    "    L1-sqrt\n",
    "       Normalization using L1-norm, followed by square root.\n",
    "    L2\n",
    "       Normalization using L2-norm.\n",
    "    L2-Hys\n",
    "       Normalization using L2-norm, followed by limiting the\n",
    "       maximum values to 0.2 (`Hys` stands for `hysteresis`) and\n",
    "       renormalization using L2-norm. (default)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "orientations    = 9\n",
    "pixels_per_cell = (8, 8)\n",
    "cells_per_block = (2, 2)\n",
    "block_norm      = 'L2' \n",
    "visualize       = False\n",
    "visualise       = None\n",
    "transform_sqrt  = True\n",
    "feature_vector  = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectolizarHOG(imagenes,esPositivo):\n",
    "    ### Esata funcion aplica HOG a todas las imagenes del diccionario\n",
    "    \n",
    "    #tamaño del vector\n",
    "    tamVector = len(hog(imagenes[0],orientations,pixels_per_cell,cells_per_block,block_norm,visualize,visualise,transform_sqrt,feature_vector))\n",
    "\n",
    "    #inicializamos la matriz que guarda los imagenes vectolizados\n",
    "    fdImagenes = np.zeros((len(imagenes),tamVector))\n",
    "    \n",
    "    for i in range(len(imagenes)):\n",
    "        fdImagenes[i,:] = hog(imagenes[i],orientations,pixels_per_cell,cells_per_block,block_norm,visualize,visualise,transform_sqrt,feature_vector)\n",
    "    \n",
    "    #asignamos el vector de clases(y) \n",
    "    if esPositivo:\n",
    "        y = np.ones((len(imagenes),1))\n",
    "    else:\n",
    "        y = np.zeros((len(imagenes),1))\n",
    "\n",
    "    return fdImagenes,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdPosTrain,yPos = vectolizarHOG(fotosPosTrain,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdNegTrain,yNeg = vectolizarHOG(fotosNegTrain,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4563, 3780)\n"
     ]
    }
   ],
   "source": [
    "fotosTrain = np.vstack((fdPosTrain,fdNegTrain))\n",
    "y = np.vstack((yPos,yNeg))\n",
    "\n",
    "print(fotosTrain.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrenamiento del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=0.007, class_weight=None, dual=True, fit_intercept=True,\n",
       "          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "          verbose=0)"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = svm.LinearSVC(C = 0.007)\n",
    "clf.fit(fotosTrain,y.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9769094138543517"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(fdPosTrain,yPos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Slide Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "winSize = 134,70"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "def slidWindow(imagen,maskHeight = 134,maskWidth = 70,step = 10):\n",
    "    arrayImagen = []\n",
    "    for i in range(0,imagen.shape[0]-maskHeight,step):        \n",
    "        for j in range(0,imagen.shape[1]-maskWidth,step):\n",
    "            arrayImagen.append((i,j,imagen[i:i+maskHeight, j:j+maskWidth]))\n",
    "    return arrayImagen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pyramid Gaussian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estudiaFoto(im,winSize,clf,ratio = 2):#Ratio de reducción\n",
    "    # List to store the detections\n",
    "    hdetections = []\n",
    "\n",
    "    for scaLev,imScaled in enumerate(pyramid_gaussian(im,downscale=ratio)):\n",
    "\n",
    "        if (imScaled.shape[0] < winSize[0] or imScaled.shape[1] < winSize[1]):\n",
    "            break\n",
    "            \n",
    "        for (x,y,imVentana) in slidWindow(imScaled,step=5):\n",
    "            fdSc = hog(imVentana,orientations,pixels_per_cell,cells_per_block,block_norm,visualize,visualise,transform_sqrt,feature_vector);\n",
    "            pred = clf.predict(fdSc.reshape(1,-1))\n",
    "            if (pred == 1):\n",
    "                hdetections.append((x,y,int(winSize[0]*ratio**scaLev),int(winSize[1]*ratio**scaLev)))\n",
    "    return hdetections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prueba del Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "def muestraResultado(detections,im):\n",
    "    for (x_tl, y_tl,w, h) in detections:\n",
    "            # Draw the detections\n",
    "            cv2.rectangle(im, (x_tl, y_tl), (x_tl+w, y_tl+h), (0, 0, 0), thickness=2)\n",
    "    cv2.imshow(\"Raw Detections before NMS\", im)\n",
    "    cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "muestraResultado(humanDetec,fotosTest[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jhonny Chicaiza\\Anaconda3\\envs\\py37vision\\lib\\site-packages\\skimage\\transform\\_warps.py:23: UserWarning: The default multichannel argument (None) is deprecated.  Please specify either True or False explicitly.  multichannel will default to False starting with release 0.16.\n",
      "  warn('The default multichannel argument (None) is deprecated.  Please '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 38.1 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jhonny Chicaiza\\Anaconda3\\envs\\py37vision\\lib\\site-packages\\skimage\\transform\\_warps.py:23: UserWarning: The default multichannel argument (None) is deprecated.  Please specify either True or False explicitly.  multichannel will default to False starting with release 0.16.\n",
      "  warn('The default multichannel argument (None) is deprecated.  Please '\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "humanDetec = estudiaFoto(fotosTest[6],winSize,clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 7.88 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "listOk = []\n",
    "partImagen = slidWindow(fotostest[6])\n",
    "for i in range(len(partImagen)):\n",
    "    pruebaHog = hog(partImagen[i][2],orientations,pixels_per_cell,cells_per_block,block_norm,visualize,visualise,transform_sqrt,feature_vector);\n",
    "    if (1 == clf.predict(pruebaHog.reshape(1,-1))):\n",
    "        listOk.append(i);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('img ', fotostest[6])\n",
    "cv2.imshow('xd ', partImagen[2291])\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48\n",
      "[113, 238, 437, 503, 836, 856, 925, 926, 1014, 1104, 1159, 1160, 1220, 1221, 1281, 1351, 1557, 1571, 1581, 1585, 1620, 1627, 1628, 1629, 1631, 1632, 1651, 1670, 1701, 1721, 1726, 1771, 1808, 1841, 1856, 1857, 1908, 1944, 1978, 2081, 2120, 2151, 2190, 2197, 2221, 2291, 2557, 2617]\n"
     ]
    }
   ],
   "source": [
    "print(len(listOk))\n",
    "print(listOk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.20889192])"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " pruebaHog = hog(partImagen[2291][2],orientations,pixels_per_cell,cells_per_block,block_norm,visualize,visualise,transform_sqrt,feature_vector,multichannel);\n",
    "clf.decision_function(pruebaHog.reshape(1,-1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py37vision] *",
   "language": "python",
   "name": "conda-env-py37vision-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
