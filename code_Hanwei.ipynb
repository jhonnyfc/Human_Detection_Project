{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Human Detection Project\n",
    "\n",
    "En este proyecto vamos a desarrollar un detector de personas en imágenes.\n",
    "\n",
    "\n",
    "## Índice del proyecto\n",
    "\n",
    "- [Lectura de imágenes](#Lectura-de-imágenes)\n",
    "    - [Fotos Train](#Fotos-Train)\n",
    "    - [Fotos Test](#Fotos-Test)\n",
    "- [Tratamiento de la imagenes Train](#Tratamiento-de-la-imagenes-Train)\n",
    "    - [Recorte Fotos Train Negativa](#Recorte-Fotos-Train-Negativa)\n",
    "    - [Ampliación Del Rango Dinámico, Suavizado y Normalización](#Ampliación-Del-Rango-Dinámico,-Suavizado-y-Normalización)\n",
    "- [Extracción de Caracterísitcas](#Extracción-de-Caracterísitcas)\n",
    "- [Entrenamiento del modelo](#Entrenamiento-del-modelo)\n",
    "- [Supresión No Maximos](#Supresión-No-Maximos)\n",
    "- [Prueba del Modelo](#Prueba-del-Modelo)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importamos todas las librerías y funciones que vamos a utilizar en este proyecto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import random\n",
    "from skimage.feature import hog\n",
    "from skimage import exposure\n",
    "from sklearn import svm\n",
    "from sklearn.decomposition import PCA\n",
    "from skimage.transform import pyramid_gaussian\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La función para mostrar imágenes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showImg(im,text = 'xd'):\n",
    "    cv2.imshow(text,im)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lectura de imágenes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La función lee desde el argumento de entrada todas las fotos del directorio y las guarda en un diccionario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def leerFotos(path):\n",
    "    os.chdir(path)\n",
    "    listaPos = os.listdir()\n",
    "    fotosDic = {}\n",
    "    for i in range(len(listaPos)):\n",
    "        fotosDic[i] = cv2.imread(listaPos[i],0)\n",
    "    return fotosDic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fotos Train "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta función crea imágenes invertidas para tener más ejemplos de Train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def duplicaTrani(fotos):\n",
    "    indx = len(fotos)\n",
    "    for i in range(len(fotos)):\n",
    "        fotos[indx+i] = cv2.flip(fotos[i], 1)\n",
    "        \n",
    "    return fotos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Leemos las imágenes Train positiva y Train negativa indicando el directorio donde se encuentran.\n",
    "(las imágenes del Train negativo hay que recortarlas posteriormente)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'C:\\\\Users\\\\Jhonny Chicaiza\\\\Desktop\\\\Human_Detection_Project-master\\\\train_pos'\n",
    "fotosPosTrain0 = leerFotos(path)\n",
    "fotosPosTrain0 = duplicaTrani(fotosPosTrain0)\n",
    "\n",
    "path = 'C:\\\\Users\\\\Jhonny Chicaiza\\\\Desktop\\\\Human_Detection_Project-master\\\\train_neg'\n",
    "fotosNegTrainSinTratar = leerFotos(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fotos Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Leemos las imágenes del Test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'C:\\\\Users\\Jhonny Chicaiza\\\\Desktop\\\\Human_Detection_Project-master\\\\Test\\\\pos'\n",
    "fotosTest0 = leerFotos(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tratamiento de la imagenes Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recorte Fotos Train Negativa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como el tamaño de las imágenes Train negativas no coincide con las Train positivas no podemos entrenarlas por HOG, por lo tanto de alguna forma hay que dejarlas con el mismo tamaño.\n",
    "\n",
    "Lo que vamos a hacer es escoger aleatoriamente en cada imagen train negativa bloques del tamaño de las Train positivas.\n",
    "\n",
    "Los parámetros de entrada son:\n",
    "* **winSize**: el tamaño del bloque\n",
    "* **dataNeg**: las fotos Train negativas sin tratar\n",
    "* **numeroCortesxPh**: número de bloques que va a sacar por cada Train negativa\n",
    "\n",
    "y nos devolve las fotos train negativas con el mismo tamaño que las positivas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generaImagenesRecortadas(winSize,dataNeg,numeroCortesxPh = 20):\n",
    "    rowsFotoPersona = winSize[0]\n",
    "    colsFotoPersona = winSize[1]\n",
    "    \n",
    "    fotosNegTrain = {}\n",
    "    for i in range(len(dataNeg)):      \n",
    "        rowsFotoEntorno = dataNeg[i].shape[0]\n",
    "        colsFotoEntorno = dataNeg[i].shape[1]\n",
    "        dimCol = colsFotoEntorno - colsFotoPersona\n",
    "        dimRow = rowsFotoEntorno - rowsFotoPersona\n",
    "        \n",
    "        for j in range(numeroCortesxPh):    \n",
    "            randRow = random.randint(0,dimRow-1)\n",
    "            randCol = random.randint(0,dimCol-1)\n",
    "            randomImage = dataNeg[i][randRow:randRow + rowsFotoPersona ,randCol: randCol + colsFotoPersona]\n",
    "            fotosNegTrain[j+numeroCortesxPh*i] = randomImage\n",
    "            \n",
    "    return fotosNegTrain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Antes de entrenar el conjunto Train vamos a hacer una serie de tratamientos a las imágenes para conseguir mejores resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "winSize = fotosPosTrain0[0].shape\n",
    "fotosNegTrain0 = generaImagenesRecortadas(winSize,fotosNegTrainSinTratar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ampliación Del Rango Dinámico, Suavizado y Normalización"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al ampliar el rango dinámico de las fotos aumentamos el contraste para un mejor extracción de características.\n",
    "\n",
    "El suavizado nos permite eliminar ruidos y detalles innecesarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ampRangoSet(fotos):\n",
    "    fotSal = {}\n",
    "    for i in range(len(fotos)):\n",
    "        r1 = np.min(fotos[i])\n",
    "        r2 = np.max(fotos[i])\n",
    "        fotSal[i] = np.float32(fotos[i])\n",
    "        fotSal[i] = 255*(fotSal[i]-r1)/(r2-r1)\n",
    "        fotSal[i] = np.uint8(fotSal[i])\n",
    "        \n",
    "    return fotSal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trataFotos(fotos,kernelSize = 3):\n",
    "    fotSal = {}\n",
    "    ## Ampliación del rango\n",
    "    fotSal = ampRangoSet(fotos)\n",
    "\n",
    "    ## Suavizado\n",
    "    #kernel = np.ones((kernelSize,kernelSize))/(kernelSize**2)\n",
    "    n = kernelSize #tamaño del filtro\n",
    "    sigma = 3 #desviación de la gaussiana\n",
    "    mask = cv2.getGaussianKernel(n, sigma)*cv2.getGaussianKernel(n, sigma).T\n",
    "    \n",
    "    for i in range(len(fotSal)):\n",
    "        fotSal[i] = cv2.filter2D(fotSal[i],-1,mask)\n",
    "        \n",
    "    return fotSal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(134, 70)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dimFiltro = 7\n",
    "fotosNegTrain = trataFotos(fotosNegTrain0,dimFiltro)\n",
    "fotosPosTrain = trataFotos(fotosPosTrain0,dimFiltro)\n",
    "fotosTest = trataFotos(fotosTest0,dimFiltro)\n",
    "\n",
    "fotosNegTrain[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracción de Caracterísitcas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algoritmo HOG (Histograma de Gradientes Orientados)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El histograma de gradientes orientados (HOG) es un descriptor de características utilizado en el procesamiento de imágenes con el fin de detectar objetos. \n",
    "\n",
    "El algoritmo divide una imagen en porciones iguales(celdas) y cuenta las ocurrencias de orientación de gradiente en cada celda.\n",
    "\n",
    "Vamos a usar la función hog de la librería skimage, Toda la información de esta función está en la URL:\n",
    "* https://scikit-image.org/docs/dev/api/skimage.feature.html#skimage.feature.hog\n",
    "* https://scikit-image.org/docs/dev/auto_examples/features_detection/plot_hog.html\n",
    "\n",
    "\n",
    "Los parámetros de entrada son:\n",
    "* **orientations**: número de orientaciones.\n",
    "* **pixels_per_cell**: tamaño de la celda.\n",
    "* **cells_per_block**: número de celdas por cada bloque.\n",
    "* **block_norm**: método de normalización de bloques:\n",
    "    * L1:\n",
    "       Normalization using L1-norm.\n",
    "    * L1-sqrt:\n",
    "       Normalization using L1-norm, followed by square root.\n",
    "    * L2:\n",
    "       Normalization using L2-norm.\n",
    "    * L2-Hys:\n",
    "       Normalization using L2-norm, followed by limiting the\n",
    "       maximum values to 0.2 (`Hys` stands for `hysteresis`) and\n",
    "       renormalization using L2-norm. (default)\n",
    "* **visualize**: devuelve la imagen procesada en la salida.\n",
    "* **visualise**: \n",
    "* **transform_sqrt**: aplica la compresión de la ley potencial para normalizar la imagen antes del procesamiento.\n",
    "* **feature_vector**: devolver los datos como un vector.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Despues de unas cuantas pruebas, definimos los parámetros de entrada:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "orientations    = 9\n",
    "pixels_per_cell = (8, 8)\n",
    "cells_per_block = (2, 2)\n",
    "block_norm      = 'L2' \n",
    "visualize       = False\n",
    "visualise       = None\n",
    "transform_sqrt  = True\n",
    "feature_vector  = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta función aplica hog a todas las fotos de entrada y devuelve un array de las características de cada imagen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "la \"y\" es la clase a la que pertenecen los ejemplos:\n",
    "* yPos = clase positiva = 1\n",
    "* yNeg = clase negativa = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def featuresExtrac(imagenes,esPositivo):    \n",
    "    ## Tamaño del vector\n",
    "    auxDim = hog(imagenes[0],orientations,pixels_per_cell,cells_per_block,block_norm,visualize,visualise,transform_sqrt,feature_vector)\n",
    "    tamHog = len(auxDim)\n",
    "    \n",
    "    #inicializamos la matriz que guarda los imagenes vectolizados\n",
    "    fdImagenesHog = np.zeros((len(imagenes),tamHog))\n",
    "    \n",
    "    for i in range(len(imagenes)):\n",
    "        fdImagenesHog[i,:] = hog(imagenes[i],orientations,pixels_per_cell,cells_per_block,block_norm,visualize,visualise,transform_sqrt,feature_vector)\n",
    "        \n",
    "    #asignamos el vector de clases(y) \n",
    "    if esPositivo:\n",
    "        y = np.ones((len(imagenes),1))\n",
    "    else:\n",
    "        y = np.zeros((len(imagenes),1))\n",
    "\n",
    "    return fdImagenesHog,y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "obtenemos la matriz de característica de las fotos Train positiva y su clase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdPosTrainHog,yPos = featuresExtrac(fotosPosTrain,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "obtenemos la matriz de característica de las fotos Train negativa y su clase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdNegTrainHog,yNeg = featuresExtrac(fotosNegTrain,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anexamos el conjunto positivo con el conjunto negativo para el entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdTrainHog = np.vstack((fdPosTrainHog,fdNegTrainHog))\n",
    "y = np.vstack((yPos,yNeg))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento del modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine (SVM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las máquinas de vectores de soporte son son un conjunto de algoritmos de aprendizaje supervisado para resolver problemas de clasificación y regresión. Dado un conjunto de ejemplos de entrenamiento (Train) podemos etiquetar las clases y entrenar una SVM para construir un modelo que prediga la clase de una nueva muestra.\n",
    "\n",
    "Creamos un clasificador SVM y lo entrenamos con las características de las imágenes Train(fdTrainHog) y su clase(y)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=0.01, class_weight=None, dual=True, fit_intercept=True,\n",
       "          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "          verbose=0)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clfHog = svm.LinearSVC(C=0.01)\n",
    "clfHog.fit(fdTrainHog[:,:],y[:,:].ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtenemos la precisión de los ejemplos positivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9893428063943162"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clfHog.score(fdPosTrainHog,yPos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtenemos la precisión de los ejemplos negativos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99975"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clfHog.score(fdNegTrainHog,yNeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como podemos ver la precisión de los ejemplos de Train es muy bueno"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Slide Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def slidWindow(imagen,maskHeight = 134,maskWidth = 70,step = 10):\n",
    "    arrayImagen = []\n",
    "    \n",
    "    for i in range(0,imagen.shape[0]-maskHeight,step):        \n",
    "        for j in range(0,imagen.shape[1]-maskWidth,step):\n",
    "            arrayImagen.append((i,j,imagen[i:i+maskHeight, j:j+maskWidth]))\n",
    "    \n",
    "    return arrayImagen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pyramid Gaussian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estudiaFoto(im,winSize,clfHog,ratio = 2,margen = 0):#Ratio de reducción\n",
    "    # List to store the detections\n",
    "    hdetections = []\n",
    "    detectJump = 0;\n",
    "    \n",
    "    for scaLev,imScaled in enumerate(pyramid_gaussian(im,downscale=ratio,multichannel=False)):\n",
    "        if (imScaled.shape[0] >= winSize[0] and imScaled.shape[1] >= winSize[1]):\n",
    "            for (x,y,imVentana) in slidWindow(imScaled):\n",
    "                if (detectJump <= 0):\n",
    "                    fdHog = hog(imVentana,orientations,pixels_per_cell,cells_per_block,block_norm,visualize,visualise,transform_sqrt,feature_vector);\n",
    "                    predHog = clfHog.predict(fdHog.reshape(1,-1))\n",
    "                    acc = clfHog.decision_function(fdHog.reshape(1,-1))[0]\n",
    "                    \n",
    "                    if (predHog == 1 and acc > margen):\n",
    "                        detectJump = 10\n",
    "                        hdetections.append((x*(ratio**scaLev),y*(ratio**scaLev),int(winSize[1]*(ratio**scaLev)),int(winSize[0]*(ratio**scaLev)),acc ))\n",
    "                detectJump -= 1;\n",
    "    return hdetections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supresión No Maximos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solapamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "def overlappingArea(detection_1, detection_2):\n",
    "    ## Calculo de las coordenadas X Y de la detecciones\n",
    "    x1_tl,y1_tl,w1,h1,_ = detection_1\n",
    "    \n",
    "    x1_br = x1_tl + h1\n",
    "    y1_br = y1_tl + w1\n",
    "    \n",
    "    x2_tl,y2_tl,w2,h2,_ = detection_2\n",
    "    \n",
    "    x2_br = x2_tl + h2\n",
    "    y2_br = y2_tl + w2\n",
    "    \n",
    "    \n",
    "    ## Calculate the overlapping Area\n",
    "    x_overlap = max(0, min(x1_br, x2_br) - max(x1_tl, x2_tl) )\n",
    "    y_overlap = max(0, min(y1_br, y2_br) - max(y1_tl, y2_tl) )\n",
    "    \n",
    "    overlap_area = x_overlap * y_overlap\n",
    "    area_1 = w1 * h1\n",
    "    area_2 = w2 * h2\n",
    "    total_area = area_1 + area_2 - overlap_area\n",
    "    \n",
    "    return overlap_area / float(total_area)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SNoM(detections, umbral  = 0):\n",
    "    GoodDetec = []\n",
    "    \n",
    "    ## Ordenamos las deteciones por coefiente de precision\n",
    "    detections = sorted(detections, key=lambda detections: detections[4],reverse=True)\n",
    "    \n",
    "    GoodDetec.append(detections[0])\n",
    "    del detections[0]\n",
    "    \n",
    "    for i,oldDetec in enumerate(detections):\n",
    "        for gDetec in GoodDetec:\n",
    "            if overlappingArea(oldDetec, gDetec) > umbral:\n",
    "                del detections[i]\n",
    "                break\n",
    "        else:\n",
    "            GoodDetec.append(oldDetec)\n",
    "            del detections[i]\n",
    "\n",
    "    return GoodDetec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prueba del Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def muestraResultado(detections,im0):\n",
    "    color = (255)\n",
    "    im = im0.copy()\n",
    "    for (x, y,w, h,_) in detections:\n",
    "            # Draw the detections\n",
    "            cv2.rectangle(im, (y, x), (y+w, x+h), color, thickness=1)\n",
    "    showImg(im,\"Deteciones\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 14.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "humanDetec = estudiaFoto(fotosTest[0],winSize,clfHog,ratio=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(humanDetec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "muestraResultado(humanDetec,fotosTest[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25\n",
      "0.25\n",
      "0.0\n",
      "0.8611111111111112\n",
      "0.0\n",
      "0.0\n",
      "0.7402597402597403\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.25\n"
     ]
    }
   ],
   "source": [
    "muestraResultado(SNoM(humanDetec,umbral = 0.1),fotosTest[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prueba solo Una imagen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "listOk = []\n",
    "partImagen = slidWindow(fotosTest[7])\n",
    "lim = 0.5\n",
    "for i in range(len(partImagen)):\n",
    "    pruebaHog = hog(partImagen[i][2],orientations,pixels_per_cell,cells_per_block,block_norm,visualize,visualise,transform_sqrt,feature_vector);\n",
    "    precis = clfHog.decision_function(pruebaHog.reshape(1,-1))[0]\n",
    "    if (1 == clfHog.predict(pruebaHog.reshape(1,-1)) and precis > lim):\n",
    "        listOk.append(i);\n",
    "        showImg(partImagen[i][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(partImagen))\n",
    "print(len(listOk))\n",
    "print(listOk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('img ', fotosTest[0])\n",
    "cv2.imshow('trozo test ', partImagen[3520][2])\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pruebaHog = hog(partImagen[3520][2],orientations,pixels_per_cell,cells_per_block,block_norm,visualize,visualise,transform_sqrt,feature_vector);\n",
    "porce = clfHog.decision_function(pruebaHog.reshape(1,-1))[0]\n",
    "print(porce)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
