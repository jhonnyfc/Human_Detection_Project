{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import random\n",
    "from skimage.feature import hog\n",
    "from skimage import exposure\n",
    "from sklearn import svm\n",
    "# from sklearn.decomposition import PCA\n",
    "# from skimage.transform import pyramid_gaussian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def leerFotos(path):\n",
    "    os.chdir(path)\n",
    "    listaPos = os.listdir()\n",
    "    fotosDic = {}\n",
    "    for i in range(len(listaPos)):\n",
    "        fotosDic[i] = cv2.imread(listaPos[i],0)\n",
    "    return fotosDic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'C:\\\\Users\\\\David\\\\Desktop\\\\Human_Detection_Project-master\\\\train_pos'\n",
    "fotosPosTrain = leerFotos(path)\n",
    "\n",
    "path = 'C:\\\\Users\\\\David\\\\Desktop\\\\Human_Detection_Project-master\\\\train_neg'\n",
    "fotosNegTrainSinTratar = leerFotos(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'C:\\\\Users\\\\David\\\\Desktop\\\\Human_Detection_Project-master\\\\Test\\\\pos'\n",
    "fotosTest = leerFotos(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "testPos = fotosPosTrain[72]\n",
    "testNeg = fotosNegTrainSinTratar[150]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ------PRETRATAMIENTO DE LAS IMAGENES POSITIVAS-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adaptamos el tamaño de las imagenes positivas a multiplo de 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recorta_imagen(imagen):    \n",
    "    return imagen[:128,:64]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "testPosRes = recorta_imagen(testPos)\n",
    "for i in range(len(fotosPosTrain)):\n",
    "    fotosPosTrain[i] = recorta_imagen(fotosPosTrain[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ampliamos el rango dinámico para obtener más contraste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ampliacion(imagen):    \n",
    "    r1 = np.min(imagen)\n",
    "    r2 = np.max(imagen)      \n",
    "    imagen = np.float32(imagen)\n",
    "    imagen = 255*(imagen-r1)/(r2-r1)\n",
    "    imagen = np.uint8(imagen)   \n",
    "    return imagen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "testPosRes = ampliacion(testPosRes)\n",
    "for i in range(len(fotosPosTrain)):\n",
    "    fotosPosTrain[i] = ampliacion(fotosPosTrain[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Suavizamos las imagenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.11111111 0.11111111 0.11111111]\n",
      " [0.11111111 0.11111111 0.11111111]\n",
      " [0.11111111 0.11111111 0.11111111]]\n"
     ]
    }
   ],
   "source": [
    "kernelSize = 3\n",
    "kernel = np.ones((kernelSize,kernelSize))/(kernelSize**2)\n",
    "print(kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "testPosRes = cv2.filter2D(testPosRes,-1,kernel)\n",
    "for i in range(len(fotosPosTrain)):\n",
    "    fotosPosTrain[i] = cv2.filter2D(fotosPosTrain[i],-1,kernel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ------PRETRATAMIENTO DE LAS IMAGENES NEGATIVAS-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tratamos las imagenes como anteriormente, ampliamos rango dinamico y suavizamos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(fotosNegTrainSinTratar)):\n",
    "    fotosNegTrainSinTratar[i] = cv2.filter2D(ampliacion(fotosNegTrainSinTratar[i]),-1,kernel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# De cada imagen, generamos unos trozos aleatorios del tamaño de las imagenes positivas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generaImagenesRecortadas(dataPos,dataNeg):    \n",
    "    numeroCortesxPh = 20      # Numero de recortadas aleatorias por foto\n",
    "    rowsFotoPersona = dataPos[0].shape[0]\n",
    "    colsFotoPersona = dataPos[0].shape[1]\n",
    "    \n",
    "    fotosNegTrain = {}\n",
    "    for i in range(len(dataNeg)):      \n",
    "        rowsFotoEntorno = dataNeg[i].shape[0]\n",
    "        colsFotoEntorno = dataNeg[i].shape[1]\n",
    "        dimCol = colsFotoEntorno - colsFotoPersona\n",
    "        dimRow = rowsFotoEntorno - rowsFotoPersona\n",
    "        \n",
    "        for j in range(numeroCortesxPh):    \n",
    "            randRow = random.randint(0,dimRow-1)\n",
    "            randCol = random.randint(0,dimCol-1)\n",
    "            randomImage = dataNeg[i][randRow:randRow + rowsFotoPersona ,randCol: randCol + colsFotoPersona]\n",
    "            fotosNegTrain[j+numeroCortesxPh*i] = randomImage\n",
    "            \n",
    "    return fotosNegTrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "fotosNegTrain = generaImagenesRecortadas(fotosPosTrain,fotosNegTrainSinTratar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creacion de los descriptores HOG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "orientations = 9\n",
    "pixels_per_cell = (8,8) \n",
    "cells_per_block = (2,2)\n",
    "block_norm = 'L2'\n",
    "visualize = False\n",
    "visualise = None\n",
    "transform_sqrt = True\n",
    "feature_vector = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectolizarHOG(imagenes,esPositivo):\n",
    "    ### Esata funcion aplica HOG a todas las imagenes del diccionario\n",
    "    \n",
    "    #tamaño del vector\n",
    "    tamVector = len(hog(imagenes[0],orientations,pixels_per_cell,cells_per_block,block_norm,visualize,visualise,transform_sqrt,feature_vector))\n",
    "\n",
    "    #inicializamos la matriz que guarda los imagenes vectolizados\n",
    "    fdImagenes = np.zeros((len(imagenes),tamVector))\n",
    "    \n",
    "    for i in range(len(imagenes)):\n",
    "        fdImagenes[i,:] = hog(imagenes[i],orientations,pixels_per_cell,cells_per_block,block_norm,visualize,visualise,transform_sqrt,feature_vector)\n",
    "    \n",
    "    #asignamos el vector de clases(y) \n",
    "    if esPositivo:\n",
    "        y = np.ones((len(imagenes),1))\n",
    "    else:\n",
    "        y = np.zeros((len(imagenes),1))\n",
    "\n",
    "    return fdImagenes,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdPosTrain,yPos = vectolizarHOG(fotosPosTrain,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdNegTrain,yNeg = vectolizarHOG(fotosNegTrain,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "fotosTrain = np.vstack((fdPosTrain,fdNegTrain))\n",
    "y = np.vstack((yPos,yNeg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrenamos el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=0.007, class_weight=None, dual=True, fit_intercept=True,\n",
       "          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "          verbose=0)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = svm.LinearSVC(C = 0.007)\n",
    "clf.fit(fotosTrain,y.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9751332149200711"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(fdPosTrain,yPos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imDetectado(im,clf,des,hPos,wPos):\n",
    "    h,w = im.shape\n",
    "    resultado = np.empty((h,w,3),dtype = np.uint8)\n",
    "    resultado[:,:,0] = im\n",
    "    resultado[:,:,1] = im\n",
    "    resultado[:,:,2] = im    \n",
    "    for i in range(0,h-hPos,des):\n",
    "        for j in range(0,w-wPos,des):\n",
    "            bloque = im[i:i+hPos,j:j+wPos]\n",
    "            fBloque = hog(bloque,orientations,pixels_per_cell,cells_per_block,block_norm,visualize,visualise,transform_sqrt,feature_vector)\n",
    "            if (clf.predict(fBloque.reshape(1,-1)) == 1):\n",
    "                resultado[i,j:j+wPos,2] = 255\n",
    "                resultado[i+hPos,j:j+wPos,2] = 255\n",
    "                resultado[i:i+hPos,j,2] = 255\n",
    "                resultado[i:i+hPos,j+wPos,2] = 255                \n",
    "    return resultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "detect = imDetectado(fotosTest[0],clf,10,128,64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(605, 1060)\n"
     ]
    }
   ],
   "source": [
    "# cv2.imshow('Original',testPos)\n",
    "# cv2.imshow('Tratada',testPosRes)\n",
    "# cv2.imshow('per',hogIm)\n",
    "print(fotosTest[0].shape)\n",
    "cv2.imshow('Test',fotosTest[0])\n",
    "cv2.imshow('Detectado',detect)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py37vision] *",
   "language": "python",
   "name": "conda-env-py37vision-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
